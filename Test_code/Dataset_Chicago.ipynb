{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import time\n",
    "import os\n",
    "from slugify import slugify # 유효한 파일명이 아니면, 유효한 파일명으로 변경해주는 library\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Data Searching with API Requests : DO NOT USE THIS!\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "base_url = \"https://api.artic.edu/api/v1/artworks\"\n",
    "pagination = requests.get(base_url + '/search' + '?limit=100&fields=fields=id,api_link,title,date_display,artist_title,dimensions,medium_display,classification_title,style_titles,image_id,artwork_type_id&query[term][artwork_type_id]=1').json()\n",
    "df = pd.DataFrame(pagination['data'])\n",
    "df = df.loc[:, [\"api_link\",\"title\", \"date_display\", \"artist_title\", \"dimensions\", \"medium_display\", \"classification_title\", \"style_titles\", \"image_id\"]]\n",
    "df= df.reset_index().drop(\"index\", axis=1)\n",
    "\n",
    "for u in range(pagination['pagination']['total_pages']):\n",
    "    page = requests.get(base_url + '/search' + '?limit=100&page='+ str(u) +'&fields=fields=id,api_link,title,date_display,artist_title,dimensions,medium_display,classification_title,style_titles,image_id,artwork_type_id&query[term][artwork_type_id]=1').json()\n",
    "    df = pd.DataFrame(page['data'])\n",
    "    df = df.loc[:, [\"api_link\",\"title\", \"date_display\", \"artist_title\", \"dimensions\", \"medium_display\", \"classification_title\", \"style_titles\", \"image_id\"]]\n",
    "    df = df.dropna(subset=[\"artist_title\", \"title\", \"image_id\"])\n",
    "    df= df.reset_index().drop(\"index\", axis=1)\n",
    "    for i in range(len(df)):\n",
    "        artist_path = os.path.join(df['artist_title'][i], slugify(df['title'][i]))\n",
    "        if not os.path.exists(df[\"artist_title\"][i]):\n",
    "            os.makedirs(df[\"artist_title\"][i])\n",
    "        if not os.path.exists(artist_path+\".jpg\"):\n",
    "            urllib.request.urlretrieve(iiif_url + \"/\"  +df[\"image_id\"][i] + \"/full/843,/0/default.jpg\", artist_path + \".jpg\" )\n",
    "            print(f'Downloading... Page : {u}, Item: {i} \\n \\tArtist : {df[\"artist_title\"][i]}, Img_title : {slugify(df[\"title\"][i])} ')\n",
    "            time.sleep(1)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "iiif_url = 'https://www.artic.edu/iiif/2'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Download Images with DUMP Data\n",
    "\"\"\"\n",
    "artist = []\n",
    "title = []\n",
    "dimension = []\n",
    "image_id = []\n",
    "\n",
    "for name in os.listdir(\"artworks\"):\n",
    "    with open(os.path.join(\"artworks\", name), \"r\") as file:\n",
    "        t = json.load(file)\n",
    "        if t['artist_title'] != None and t['title'] != None and t['image_id'] != None and t['artwork_type_id'] == 1:\n",
    "            artist.append(t['artist_title'])\n",
    "            title.append(t['title'])\n",
    "            dimension.append(t['dimensions'])\n",
    "            image_id.append(t['image_id'])\n",
    "\n",
    "            artist_path = os.path.join(t['artist_title'], slugify(t['title']))\n",
    "            try:\n",
    "                if not os.path.exists(t[\"artist_title\"]):\n",
    "                    os.makedirs(t[\"artist_title\"])\n",
    "                if not os.path.exists(artist_path+\".jpg\"):\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(iiif_url + \"/\"  +t[\"image_id\"] + \"/full/843,/0/default.jpg\", artist_path + \".jpg\" )\n",
    "                        print(f'Downloading... \\tArtist : {t[\"artist_title\"]}, Img_title : {slugify(t[\"title\"])} ')\n",
    "                        time.sleep(1)\n",
    "                    except urllib.error.HTTPError:\n",
    "                        print(f'Error Occured : {t[\"id\"]}, Img_title : {t[\"title\"]}')\n",
    "                else:\n",
    "                    print(f'{t[\"id\"]}\\t{slugify(t[\"title\"])} is already downloaded!!')\n",
    "            except OSError:\n",
    "                print(f'OSError : {t[\"id\"]}, \\tArtist : {t[\"artist_title\"]}, \\tImg_title : {t[\"title\"]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}